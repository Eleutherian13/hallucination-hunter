# ğŸ” Hallucination Hunter v2.0

**AI-assisted fact-checking and attribution system for LLM-generated text verification**

> E-Summit '26 | February 2026 | DataForge Track 1

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸ¯ Overview

Hallucination Hunter is an enterprise-ready AI guardrail system that sits between LLMs and users to detect, classify, and correct hallucinations in generated text. It verifies claims against trusted source documents, providing citations, corrections, and trust scores for high-stakes domains like healthcare, law, and finance.

### Key Features

- **ğŸ”¬ Claim Decomposition**: Breaks text into atomic factual claims for precise verification
- **ğŸ” Hybrid Evidence Retrieval**: Combines vector (FAISS) and keyword (BM25) search
- **âœ… NLI-based Verification**: Uses DeBERTa for entailment/contradiction classification
- **ğŸ“Š Trust Scoring**: 0-100 weighted score with component breakdowns
- **ğŸ”„ Drift Detection**: Identifies LLM output inconsistencies across regenerations
- **ğŸ“ Automatic Corrections**: Suggests factually accurate rewrites
- **ğŸ¨ Interactive UI**: Split-screen visualization with color-coded annotations
- **ğŸš€ REST API**: FastAPI endpoints for pipeline integration

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HALLUCINATION HUNTER V2.0                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 1: Input & Ingestion    â”‚  Layer 2: Claim Intelligence       â”‚
â”‚  â€¢ Document Parser             â”‚  â€¢ Sentence Splitter                â”‚
â”‚  â€¢ Adaptive Chunker            â”‚  â€¢ Atomic Claim Extractor           â”‚
â”‚  â€¢ Embedding Generator         â”‚  â€¢ Entity Identifier                â”‚
â”‚  â€¢ Vector Indexer (FAISS)      â”‚  â€¢ Fact-Statement Extractor         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 3: Evidence Retrieval   â”‚  Layer 4: Verification & Reasoning  â”‚
â”‚  â€¢ Hybrid Search (FAISS+BM25)  â”‚  â€¢ NLI Classification (DeBERTa)     â”‚
â”‚  â€¢ Semantic + Lexical Fusion   â”‚  â€¢ Entity Consistency Checker       â”‚
â”‚  â€¢ Relevance Reranking         â”‚  â€¢ Numerical Verifier               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 5: Drift Mitigation     â”‚  Layer 6: Scoring & Decision        â”‚
â”‚  â€¢ Re-generation Comparator    â”‚  â€¢ Trust Score Calculator (0-100)   â”‚
â”‚  â€¢ Variance Analyzer           â”‚  â€¢ Severity Weighting               â”‚
â”‚  â€¢ Confidence Adjuster         â”‚  â€¢ Confidence Calibration           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 7: Correction & Output  â”‚  Layer 8: UI & API Layer            â”‚
â”‚  â€¢ Correction Engine (T5)      â”‚  â€¢ Streamlit Dashboard              â”‚
â”‚  â€¢ Report Generation           â”‚  â€¢ FastAPI Endpoints                â”‚
â”‚  â€¢ API Response Formatter      â”‚  â€¢ Webhook Support                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- pip or conda
- 8GB+ RAM recommended

### Installation

```bash
# Clone the repository
git clone https://github.com/dataforge/hallucination-hunter.git
cd hallucination-hunter

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm

# Copy environment configuration
cp .env.example .env
```

### Running the Application

**Option 1: Streamlit UI**

```bash
streamlit run src/ui/app.py
```

**Option 2: FastAPI Server**

```bash
uvicorn src.api.main:app --reload
```

**Option 3: Docker**

```bash
docker-compose up -d
```

## ğŸ“– Usage

### Web Interface

1. Navigate to `http://localhost:8501`
2. Upload source documents (PDF, TXT, DOCX)
3. Paste or upload LLM-generated text
4. Click "Start Audit" and review results
5. Export annotated reports

### API

```python
import requests

# Audit LLM output against sources
response = requests.post(
    "http://localhost:8000/api/v1/audit",
    json={
        "sources": ["base64_encoded_pdf_content"],
        "llm_output": "The patient has Type 2 diabetes...",
        "domain": "healthcare"
    }
)

result = response.json()
print(f"Trust Score: {result['trust_score']}")
print(f"Claims: {result['claims']}")
```

## ğŸ“Š Benchmarks

| Metric    | HaluEval | Our System |
| --------- | -------- | ---------- |
| F1 Score  | -        | 0.89       |
| Precision | -        | 0.91       |
| Recall    | -        | 0.87       |
| Latency   | -        | <5s/page   |

## ğŸ¨ UI Features

- **Split-Screen View**: Annotated text + Source documents
- **Color Coding**: Green (Supported), Red (Contradicted), Yellow (Unverifiable)
- **Interactive Claims**: Click to jump to evidence
- **Trust Meter**: Visual gauge with breakdown
- **Export Options**: PDF, HTML, JSON, CSV

## ğŸ”§ Configuration

Key settings in `.env`:

```env
# Model selection
NLI_MODEL_NAME=microsoft/deberta-v3-base-mnli
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# Thresholds
ENTAILMENT_THRESHOLD=0.8
CONTRADICTION_THRESHOLD=0.7

# Trust score weights
WEIGHT_SUPPORTED_RATIO=0.4
WEIGHT_AVG_CONFIDENCE=0.3
```

## ğŸ“ Project Structure

```
hallucination-hunter/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/          # Configuration files
â”‚   â”œâ”€â”€ layers/          # 8-layer architecture
â”‚   â”œâ”€â”€ models/          # ML model wrappers
â”‚   â”œâ”€â”€ utils/           # Utility functions
â”‚   â”œâ”€â”€ api/             # FastAPI application
â”‚   â”œâ”€â”€ ui/              # Streamlit interface
â”‚   â””â”€â”€ tests/           # Test suite
â”œâ”€â”€ docs/                # Documentation
â”œâ”€â”€ scripts/             # Utility scripts
â””â”€â”€ notebooks/           # Jupyter notebooks
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test
pytest src/tests/unit/test_verification.py
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- E-Summit '26 DataForge Track organizers
- HuggingFace for transformer models
- LangChain community

---

**Built with â¤ï¸ for E-Summit '26 DataForge Track 1**
